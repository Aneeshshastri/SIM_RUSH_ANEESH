
# The Solar Flare Pulse: Stochastic Signal Recovery
![Python Version](https://img.shields.io/badge/python-3.13%2B-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Status](https://img.shields.io/badge/status-complete-success)
##  Project Overview

This project implements a **Bayesian Parameter Estimation** pipeline to recover the physical properties of a stellar flare event from heavily noise-corrupted time-series data.

Developed as part of the **Simulation Rush** [By Elan and nVision] , the solution utilizes a **Metropolis-Hastings Markov Chain Monte Carlo (MCMC)** algorithm to reconstruct latent parameters despite significant stochastic noise and signal dropouts. A key innovation of this implementation is the development of a robust **Mixed Error Model** to resolve numerical stability issues inherent in relative error models at signal zero-crossings.

##  Key Features

* **Robust Likelihood Function:** Implements a mathematically rigorous "Mixed Error Model" () to preven
* **Automated Noise Calibration:** Utilizes stochastic global optimization (Differential Evolution) nested within a root-finding algorithm to statistically determine the optimal instrumental noise floor ().
* **Adaptive MCMC Strategy:** Features a pilot tuning phase using Robbins-Monro stochastic approximation to learn the parameter covariance structure, followed by a stationary Metropolis-Hastings production run.
* **Precision MAP Estimation:** Extracts Maximum A Posteriori (MAP) estimates using guassian KDE

---

##  Repository Structure

```text
.
├── flare_data.csv       # Input: The noisy time-series sensor data
├── Solution.ipynb       # Main: Complete analysis pipeline (Optimization + MCMC+ Visualisation)
├── LICENSE              # License: MIT License, used for this repository
├── README.md            # Documentation: Project overview and usage
├── requirements.txt     # Dependencies: Python libraries required
├ SIMULATION RUSH PS.pdf # Documentation: Original Problem statement for the project
├Simulation_Rush_Report.pdf # Documentation: project report
└── output/              # Output: Generated visualization artifacts
    ├── Sigma_burnin.jpg     # Robbins Monro MCMC sigma vs. iterations
    ├── Traceplot.jpg        # Traceplots of MH MCMC to check convergence
    ├── posterior_distribution.jpg # Posterior probability distributions of the three parameters (kdeplots)
    └── fit_check.jpg #final model (with MAP parameters) vs. raw data


```

---

##  Installation & Configuration

### 1. Prerequisites

Ensure you have **Python 3.13** or higher installed.

### 2. Environment Setup

It is recommended to run this project in a virtual environment.

```bash
# Create virtual environment
python -m venv venv

# Activate environment (Windows)
venv\Scripts\activate

# Activate environment (Mac/Linux)
source venv/bin/activate

```
If you're using Conda for your environment instead 
```bash
# Create virtual environment in (conda prompt)
conda create --name <env_name> python=3.13.5
conda activate <env_name>

```

### 3. Install Dependencies

Install the required scientific computing libraries using `pip`.

```bash
pip install -r requirements.txt

```

---

##  Usage Instructions

1. **Prepare Data:** Ensure `flare_data.csv` is present in the root directory.
2. **Run Analysis:** Execute the main script. (Open your file on a Jupyter Notebook Environment (like colab, Jupyter, kaggle etc.) and run all cells



### Execution Flow

The script performs the following steps automatically:

1. **Noise Floor Optimization:** Solves for the instrumental noise floor parameter  such that the Reduced Chi-Squared statistic equals 1.0.
2. **Pilot Tuning** : Initializes and runs Robbins-Monro MCMC and uses the results to generate a covariance matrix
3. **MCMC Sampling:** Initializes a Metropolis-Hastings sampler and runs for 400,000 iterations.
4. **Sanity Check:** Validates the derived model against the raw data.
5. **Visualization:** Generates and saves plots to the `output/` directory.

---

## cientific Methodology

### 1. The Physical Model

The flare intensity  is modeled by the analytical function:

$S(t; A, \tau, \omega) = A e^t \left[ 1 - \tanh(2(t - \tau)) \right] \sin(\omega t)$
### 2. Statistical Challenge & Solution

The problem statement specifies a relative error model . This creates a mathematical trap where  as , causing the Likelihood function to diverge to infinity at zero-crossings.

**Our Solution:** We implemented a **Mixed Error Model**:

$\sigma_i = 0.2 \cdot |y_i| + \sigma_{\text{floor}}$

(where $\sigma_{\text{floor}} = k \cdot \sigma_{\text{data}}$)

We numerically solved for the hyperparameter (k), which stabilizes the likelihood function and ensures the error bars are physically consistent with the observed data variance.

---

## Results

Typical results generated by this pipeline:

| Parameter | Symbol | Estimate (Mean ± ) |
| --- | --- | --- |
| **Noise Floor** | $k$ | `0.3746` (Optimized) |
| **Amplitude** | $A$ | `0.2426  ± 0.0095` |
| **Quench Time** | $\tau$ | `5.066  ± 0.0280` |
| **Frequency** | $\omega$ | `10.001 ± 0.0047` |

**Goodness of Fit:**  Ideal statistical fit, and had achieved a reduced Chi-squared of 0.99995

---

##  Requirements

```text
numpy>=2.1.0
pandas>=2.2.0
scipy>=1.14.0
matplotlib>=3.9.0
seaborn>=0.13.0
```

---

## Author

**Team: Lone Star**

* Aneesh Shastri 


